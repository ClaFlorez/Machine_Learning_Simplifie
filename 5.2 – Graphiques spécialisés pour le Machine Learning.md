# ğŸ“Š 5.2 â€“ Graphiques spÃ©cialisÃ©s pour le Machine Learning

## ğŸ¯ Objectif du chapitre
Au-delÃ  des histogrammes et scatter plots classiques, le **Machine Learning** utilise des graphiques spÃ©cifiques pour :
- Comprendre les **variables (features)** avant lâ€™entraÃ®nement
- Visualiser les **performances des modÃ¨les**
- Suivre les **courbes dâ€™apprentissage et de validation**
- InterprÃ©ter les **matrices de confusion**
- Diagnostiquer les **problÃ¨mes de surapprentissage ou sous-apprentissage**

---

## ğŸ” 1. Pairplot â€“ Relations entre toutes les variables

### ğŸ§  DÃ©finition
Un **pairplot** (grille de scatter plots) permet de :
- Visualiser la **relation entre chaque paire de variables**
- Observer les **distributions individuelles** (diagonale)
- DÃ©tecter rapidement des **corrÃ©lations** ou **clusters**

### ğŸ“Š Exemple
Imaginons un dataset simplifiÃ© sur lâ€™iris (fleurs) :

```python
import seaborn as sns
import matplotlib.pyplot as plt

# Charger un dataset intÃ©grÃ©
iris = sns.load_dataset("iris")

# CrÃ©er le pairplot
sns.pairplot(iris, hue="species", diag_kind="kde")
plt.show()
```
## ğŸŒ¸ Pairplot â€“ Relations entre toutes les variables (Dataset Iris)

Le graphique ci-dessous est un **pairplot**, gÃ©nÃ©rÃ© avec Seaborn, qui permet de visualiser **toutes les relations possibles entre les variables** du dataset Iris.  

![Pairplot â€“ Relations Iris](image/relations-entre-toutes-les-variables-Pairplot-complet.JPG)

### ğŸ” Comment lire ce graphique ?

- **Diagonale principale** :  
  On observe des histogrammes reprÃ©sentant la **distribution individuelle** de chaque variable (`sepal length`, `sepal width`, `petal length`, `petal width`).

- **Hors diagonale** :  
  Chaque case est un **nuage de points** qui compare deux variables entre elles.  
  Par exemple : `petal length` vs `petal width`.

- **Couleurs** :  
  Les points sont colorÃ©s selon la **classe de la fleur** (`setosa`, `versicolor`, `virginica`).  
  Cela permet de voir la **sÃ©parabilitÃ© potentielle** entre espÃ¨ces.

### ğŸ“Š Analyse des rÃ©sultats

1. **SÃ©parabilitÃ© claire** :  
   - `setosa` (bleu) est bien sÃ©parÃ©e des deux autres classes, surtout avec les variables de pÃ©tales.  
   - `versicolor` (orange) et `virginica` (vert) se chevauchent un peu, mais restent distinguables.

2. **Variables les plus discriminantes** :  
   - Les variables liÃ©es aux **pÃ©tales** (longueur et largeur) offrent une bien meilleure sÃ©paration que celles liÃ©es aux sÃ©pales.

3. **CorrÃ©lations visibles** :  
   - `petal length` et `petal width` prÃ©sentent une **forte corrÃ©lation positive** (les deux augmentent ensemble).  
   - `sepal length` est aussi corrÃ©lÃ© avec `petal length`.  
   - `sepal width` est la variable la moins corrÃ©lÃ©e avec les autres.

### ğŸ“Œ CorrÃ©lations numÃ©riques principales

- `petal length (cm)` â†” `petal width (cm)` : **0.963** (corrÃ©lation trÃ¨s forte âœ…)  
- `sepal length (cm)` â†” `petal length (cm)` : **0.872**  
- `sepal length (cm)` â†” `petal width (cm)` : **0.818**

---

ğŸ‘‰ **En rÃ©sumÃ©** :  
Le pairplot est un outil puissant dâ€™**analyse exploratoire (EDA)** qui permet de :  
- dÃ©tecter les **corrÃ©lations fortes**,  
- identifier les **variables discriminantes** pour un futur modÃ¨le de classification,  
- et repÃ©rer rapidement la **sÃ©parabilitÃ© entre classes**.

##2. Feature Importance - Importance des variables
##Objectif : Identifier quelles variables sont les plus utiles pour la prÃ©diction

###Feature Importance complÃ¨te

## ğŸ· Importance des variables â€“ Classification des vins

Le graphique ci-dessous montre lâ€™**importance relative des variables** utilisÃ©es pour prÃ©dire la classe dâ€™un vin.  
Cette visualisation est typique des modÃ¨les comme les **arbres de dÃ©cision** ou les **forÃªts alÃ©atoires**.

![Feature Importance â€“ Vins](image/Feature_Importance_complete.JPG)

---

### ğŸ” Comment lire ce graphique ?

- **Axe horizontal (Importance)** : indique le poids relatif de chaque variable dans le modÃ¨le.
- **Barres colorÃ©es** : plus une barre est longue, plus la variable contribue Ã  la prÃ©diction.
- **Classement dÃ©croissant** : les variables les plus importantes apparaissent en haut.

---

### ğŸ“Š Analyse des rÃ©sultats

1. **Variables dominantes** :
   - **Flavanoids** : 0.202 â†’ la variable la plus discriminante.  
   - **Color intensity** : 0.171 â†’ deuxiÃ¨me variable clÃ©.  
   - **Proline** : 0.139.  
   - **Alcohol** et **OD280/OD315 of diluted wines** : 0.112 chacun.

   ğŸ‘‰ Ã€ elles seules, ces 5 variables expliquent la **majeure partie des diffÃ©rences entre classes de vins**.

2. **Variables secondaires** :  
   - `hue`, `magnesium`, `malic_acid` contribuent mais beaucoup moins (entre 0.036 et 0.071).  

3. **Variables mineures** :  
   - `nonflavanoid_phenols`, `proanthocyanins`, `ash` â†’ importances trÃ¨s faibles (< 0.03).

---

### ğŸ“Œ Statistiques complÃ©mentaires

- **Top 5 des variables les plus importantes** :
  1. flavanoids â†’ 0.202  
  2. color_intensity â†’ 0.171  
  3. proline â†’ 0.139  
  4. alcohol â†’ 0.112  
  5. od280/od315_df_diluted_wines â†’ 0.112  

- **Contribution cumulative** :
  - 2 variables suffisent Ã  expliquer ~37% de lâ€™importance.  
  - 5 variables â†’ ~73%.  

- **Performance du modÃ¨le** :
  - Score dâ€™entraÃ®nement : 1.000  
  - Score de test : 1.000 âœ…

---

ğŸ‘‰ **En rÃ©sumÃ©** :  
Ce graphique montre que quelques variables (flavanoids, color_intensity, proline) sont largement suffisantes pour classer les vins avec une prÃ©cision quasi parfaite. Les autres variables ont un rÃ´le secondaire ou redondant.


## ğŸ» Violin Plot â€“ Distribution des valeurs par groupe

Le **violin plot** combine deux Ã©lÃ©ments en un seul graphique :
- Un **boxplot** (boÃ®te et moustaches) qui rÃ©sume les statistiques principales (mÃ©diane, quartiles, valeurs extrÃªmes).
- Une **courbe de densitÃ©** symÃ©trique qui montre la forme complÃ¨te de la distribution.

![Violin Plot](image/violin-plot.JPG)

---

### ğŸ” Comment lire ce graphique ?

- **Largeur du violon** : indique la densitÃ© des donnÃ©es (plus large = plus de valeurs Ã  ce niveau).
- **BoÃ®te interne** : reprÃ©sente lâ€™intervalle interquartile (50 % des donnÃ©es).
- **Ligne centrale** : la **mÃ©diane** (valeur centrale des donnÃ©es).
- **Points extrÃªmes** : valeurs aberrantes ou outliers.

---

### ğŸ“Š Analyse par groupe

**Groupe A**  
- Moyenne : ~42.6  
- MÃ©diane : 40.5  
- Distribution : relativement symÃ©trique, densitÃ© concentrÃ©e autour de 40-50.  
- Intervalle : [32.8 ; 77.2]  

**Groupe B**  
- Moyenne : ~54.4  
- MÃ©diane : 54.3  
- Distribution : lÃ©gÃ¨rement symÃ©trique, densitÃ© homogÃ¨ne.  
- Intervalle : [18.6 ; 75.9]  

**Groupe C**  
- Moyenne : ~39.3  
- MÃ©diane : 39.1  
- Distribution : plus Ã©talÃ©e avec quelques valeurs trÃ¨s hautes (jusquâ€™Ã  ~150).  
- AsymÃ©trie : **droite** (quelques valeurs extrÃªmes tirent la distribution vers le haut).  

**Groupe D**  
- Moyenne : ~45.5  
- MÃ©diane : 45.3  
- Distribution : forme Ã©quilibrÃ©e, mais avec plusieurs petites concentrations locales.  
- Intervalle : [24.2 ; 59.3]  

---

### ğŸ“Œ Points clÃ©s Ã  retenir

- Le **Groupe B** a les valeurs les plus Ã©levÃ©es en moyenne.  
- Le **Groupe C** prÃ©sente une **forte variabilitÃ©** et des outliers extrÃªmes.  
- Les **Groupes A et D** sont plus stables et homogÃ¨nes.  
- Le violin plot permet de comparer dâ€™un coup dâ€™Å“il **forme, symÃ©trie et dispersion** entre plusieurs distributions.

ğŸ‘‰ **En rÃ©sumÃ©** : le violin plot est un outil puissant pour visualiser la **forme complÃ¨te dâ€™une distribution** tout en conservant les informations du boxplot.

## ğŸ”¢ Matrice de Confusion â€“ Classification des Chiffres

La **matrice de confusion** est un outil central pour Ã©valuer les performances dâ€™un modÃ¨le de classification.  
Elle compare les **prÃ©dictions du modÃ¨le** (colonnes) avec les **valeurs rÃ©elles** (lignes).

![Matrice de confusion â€“ Chiffres](image/matrice-de-confusion.JPG)

---

### ğŸ” Comment lire cette matrice ?

- **Diagonale principale** (cases foncÃ©es) : nombre de prÃ©dictions correctes pour chaque chiffre.  
- **Cases hors diagonale** : erreurs de classification â†’ la vraie classe a Ã©tÃ© confondue avec une autre.  
- **Couleur** : plus la case est foncÃ©e, plus le nombre dâ€™occurrences est Ã©levÃ©.  

---

### ğŸ“Š Analyse des rÃ©sultats

- **PrÃ©cision globale** : **0.973** â†’ le modÃ¨le prÃ©dit correctement 97.3 % des cas.  
- **Total de prÃ©dictions correctes** : 358 / 368.  

#### âœ… Performances par chiffre :
- **Chiffre 0** : PrÃ©cision = 1.000, Rappel = 0.970  
- **Chiffre 1** : PrÃ©cision = 0.966, Rappel = 1.000  
- **Chiffre 4** : PrÃ©cision = 1.000, Rappel = 0.981  
- **Chiffre 9** : PrÃ©cision = 0.974, Rappel = 0.950  

ğŸ‘‰ Tous les chiffres ont une **prÃ©cision et un rappel supÃ©rieurs Ã  0.95**, ce qui indique un modÃ¨le trÃ¨s robuste.

---

### âš ï¸ Confusions les plus frÃ©quentes

- 1 fois : le **5** a Ã©tÃ© prÃ©dit comme **3**  
- 1 fois : le **6** a Ã©tÃ© prÃ©dit comme **5**  
- 1 fois : le **7** a Ã©tÃ© prÃ©dit comme **9**  
- 1 fois : le **8** a Ã©tÃ© prÃ©dit comme **9**

ğŸ‘‰ Ces erreurs sont logiques : ce sont des chiffres visuellement proches.

---

### ğŸ“Œ Rapport dÃ©taillÃ© (precision, recall, F1-score)

| Chiffre | Precision | Recall | F1-score | Support |
|---------|-----------|--------|----------|---------|
| 0       | 1.00      | 0.97   | 0.99     | 33      |
| 1       | 0.97      | 1.00   | 0.99     | 28      |
| 2       | 1.00      | 1.00   | 1.00     | 33      |
| 3       | 0.97      | 0.97   | 0.97     | 33      |
| 4       | 1.00      | 0.98   | 0.99     | 32      |
| 5       | 0.96      | 0.98   | 0.97     | 46      |
| 6       | 0.97      | 0.97   | 0.97     | 34      |
| 7       | 0.97      | 0.97   | 0.97     | 33      |
| 8       | 0.97      | 0.97   | 0.97     | 30      |
| 9       | 0.97      | 0.95   | 0.96     | 39      |

- **Accuracy globale** : 0.97  
- **Macro avg** (moyenne par classe) : Precision = 0.97, Recall = 0.97, F1 = 0.97  
- **Weighted avg** (pondÃ©rÃ©e) : identique Ã  la macro, confirmant un bon Ã©quilibre entre classes.

---

ğŸ‘‰ **En rÃ©sumÃ©** :  
Cette matrice de confusion montre que le modÃ¨le est **trÃ¨s performant (97 % de prÃ©cision)**.  
Les erreurs sont rares et se concentrent uniquement sur des chiffres visuellement similaires (5/3, 7/9, etc.).  
Câ€™est un excellent indicateur que le modÃ¨le est prÃªt pour une utilisation pratique.

## ğŸ“ˆ Courbes ROC â€“ Comparaison de modÃ¨les

Les **courbes ROC (Receiver Operating Characteristic)** permettent dâ€™Ã©valuer la capacitÃ© dâ€™un modÃ¨le de classification Ã  distinguer les classes positives et nÃ©gatives.  
Elles tracent la **sensibilitÃ© (True Positive Rate)** en fonction du **taux de faux positifs (1 - SpÃ©cificitÃ©)**.

![Courbes ROC](image/curbes-ROC.JPG)

---

### ğŸ” Comment lire ce graphique ?

- **Axe horizontal (X)** : taux de faux positifs (1 - spÃ©cificitÃ©).  
- **Axe vertical (Y)** : taux de vrais positifs (sensibilitÃ©).  
- **Courbe idÃ©ale** : monte rapidement vers le coin supÃ©rieur gauche (sensibilitÃ© maximale avec peu de faux positifs).  
- **Ligne en diagonale (AUC = 0.5)** : modÃ¨le alÃ©atoire, sans pouvoir prÃ©dictif.  

---

### ğŸ“Š Analyse des rÃ©sultats

- **Random Forest** : AUC = **0.986** â†’ Excellent modÃ¨le.  
- **RÃ©gression logistique** : AUC = **0.982** â†’ TrÃ¨s performant.  
- **SVM** : AUC = **0.989** â†’ Meilleur modÃ¨le global.  
- **Classificateur alÃ©atoire** : AUC = **0.5** â†’ RÃ©fÃ©rence de hasard.  

ğŸ‘‰ Tous les modÃ¨les testÃ©s ont une performance **excellente (AUC > 0.98)**.

---

### ğŸ“Œ InterprÃ©tation des valeurs AUC

- **AUC = 1.0** : modÃ¨le parfait.  
- **AUC = 0.9 â€“ 1.0** : excellent modÃ¨le.  
- **AUC = 0.8 â€“ 0.9** : bon modÃ¨le.  
- **AUC = 0.5** : modÃ¨le alÃ©atoire.  

---

### âœ… Meilleur modÃ¨le identifiÃ© : **SVM**

- **Seuil optimal** : 0.591  
- **SensibilitÃ©** au seuil optimal : 0.991  
- **SpÃ©cificitÃ©** au seuil optimal : 0.978  

Cela signifie que le SVM dÃ©tecte presque toutes les instances positives tout en maintenant un taux de faux positifs trÃ¨s faible.

---

ğŸ‘‰ **En rÃ©sumÃ©** :  
Les courbes ROC montrent que les trois modÃ¨les (Random Forest, Logistic Regression, SVM) sont trÃ¨s puissants pour cette tÃ¢che.  
Le **SVM est lÃ©gÃ¨rement supÃ©rieur**, atteignant un compromis idÃ©al entre **sensibilitÃ©** et **spÃ©cificitÃ©**.


## ğŸ“š Courbes dâ€™apprentissage â€“ Random Forest

La **courbe dâ€™apprentissage** montre comment les performances dâ€™un modÃ¨le Ã©voluent en fonction de la **taille de lâ€™Ã©chantillon dâ€™entraÃ®nement**.  
Elle compare le **score dâ€™entraÃ®nement** et le **score de validation**.

![Courbes dâ€™apprentissage â€“ Random Forest](image/curbes-d-aprentisage-random-forest.JPG)

---

### ğŸ” Comment lire ce graphique ?

- **Courbe rouge** : prÃ©cision du modÃ¨le sur les donnÃ©es dâ€™entraÃ®nement.  
- **Courbe verte** : prÃ©cision sur les donnÃ©es de validation (non vues).  
- **Zone verte claire** : intervalle de confiance (variabilitÃ© du modÃ¨le selon les sous-Ã©chantillons).  
- **Axe X** : nombre dâ€™exemples utilisÃ©s pour lâ€™entraÃ®nement.  
- **Axe Y** : score de prÃ©cision obtenu.

---

### ğŸ“Š Analyse des rÃ©sultats

- **Score final entraÃ®nement** : **1.000** (le modÃ¨le apprend parfaitement les donnÃ©es dâ€™entraÃ®nement).  
- **Score final validation** : **0.961** (excellente gÃ©nÃ©ralisation).  
- **Ã‰cart entre courbes (overfitting)** : **0.039** â†’ trÃ¨s faible, donc pas de surapprentissage significatif.  

ğŸ‘‰ Le modÃ¨le est **bien Ã©quilibrÃ©** : il apprend bien sans trop se spÃ©cialiser sur lâ€™entraÃ®nement.

---

### âš ï¸ Diagnostic

- **ModÃ¨le Ã©quilibrÃ© âœ…** :  
  Le Random Forest gÃ©nÃ©ralise correctement.  
- **Variance faible** : peu de fluctuation des scores de validation (~0.005).  
- **AmÃ©lioration possible** : un ajout de donnÃ©es dâ€™entraÃ®nement pourrait lÃ©gÃ¨rement augmenter le score de validation (actuellement ~96.1 %).  

---

### ğŸ“Œ Points clÃ©s Ã  retenir

- Les deux courbes convergent â†’ bon signe de stabilitÃ©.  
- Un **Ã©cart faible (0.039)** montre une bonne capacitÃ© de gÃ©nÃ©ralisation.  
- Le Random Forest est un modÃ¨le robuste pour ce dataset.  

ğŸ‘‰ **En rÃ©sumÃ©** :  
Cette courbe dâ€™apprentissage prouve que le modÃ¨le **Random Forest est performant et bien rÃ©gularisÃ©**.  
Il atteint une prÃ©cision trÃ¨s Ã©levÃ©e sans souffrir dâ€™overfitting, et pourrait encore progresser avec davantage de donnÃ©es.

## ğŸ“Š Analyse complÃ¨te des rÃ©sidus â€“ Diagnostic de modÃ¨le

Lâ€™analyse des **rÃ©sidus** permet de vÃ©rifier si un modÃ¨le respecte les hypothÃ¨ses fondamentales de la rÃ©gression (normalitÃ©, indÃ©pendance, variance constante).  


![Analyse des rÃ©sidus](image/analyse-complete-de-residus.JPG)

---

### ğŸ” Contenu du graphique

1. **RÃ©sidus vs PrÃ©dictions (en haut Ã  gauche)**  
   - VÃ©rifie si les rÃ©sidus sont rÃ©partis alÃ©atoirement.  
   - Ici, la dispersion est globalement homogÃ¨ne, ce qui indique une bonne qualitÃ© de prÃ©diction.

2. **Distribution des rÃ©sidus (en haut Ã  droite)**  
   - Histogramme des rÃ©sidus comparÃ© Ã  une distribution normale (courbe rouge).  
   - Les rÃ©sidus semblent suivre une distribution proche de la normale.

3. **Q-Q Plot des rÃ©sidus (en bas Ã  gauche)**  
   - Compare les quantiles des rÃ©sidus aux quantiles thÃ©oriques dâ€™une loi normale.  
   - Les points suivent bien la diagonale â†’ normalitÃ© respectÃ©e.

4. **RÃ©sidus vs Ordre des observations (en bas Ã  droite)**  
   - Permet de dÃ©tecter une autocorrÃ©lation Ã©ventuelle.  
   - Les rÃ©sidus oscillent autour de 0 sans tendance â†’ indÃ©pendance respectÃ©e.

---

### ğŸ“Š Diagnostic statistique

- **Test de normalitÃ© (Shapiro-Wilk)** :  
  - Statistique = 0.994  
  - p-value = 0.8503  
  âœ… Les rÃ©sidus suivent une distribution normale.

- **Statistiques descriptives** :  
  - Moyenne â‰ˆ 12.05  
  - MÃ©diane â‰ˆ 21.16  
  - Ã‰cart-type â‰ˆ 62.36  
  - AsymÃ©trie â‰ˆ 0.26 (faible)  
  - Aplatissement (kurtosis) â‰ˆ 0.51  

- **Test dâ€™homoscÃ©dasticitÃ©** :  
  - CorrÃ©lation rÃ©sidus vs prÃ©dictions = 0.0057  
  âœ… Variance constante (pas dâ€™hÃ©tÃ©roscÃ©dasticitÃ©).

---

### ğŸ“Œ MÃ©triques de performance

- **RÂ²** : 0.8236 (le modÃ¨le explique ~82 % de la variance).  
- **MAE** : 42.35 (erreur moyenne absolue).  
- **MSE** : 2245.39 (erreur quadratique).  
- **RMSE** : 47.39 (erreur standard en unitÃ©s des donnÃ©es).

---

### âœ… Conclusion

- Les rÃ©sidus suivent une **distribution normale**.  
- Pas de signe dâ€™**hÃ©tÃ©roscÃ©dasticitÃ©** ni dâ€™**autocorrÃ©lation**.  
- Le modÃ¨le est **robuste** avec un **RÂ² = 0.82**, indiquant une bonne capacitÃ© explicative.  

ğŸ‘‰ Cette analyse confirme que les hypothÃ¨ses de la rÃ©gression sont respectÃ©es et que le modÃ¨le est fiable.




# ğŸ“˜ Module 5 â€“ Visualisation et Diagnostic des ModÃ¨les

Ce chapitre regroupe toutes les Ã©tapes de lâ€™**exploration visuelle des donnÃ©es (EDA)** et des **graphiques spÃ©cialisÃ©s pour le Machine Learning**.  
Chaque graphique est accompagnÃ© dâ€™une explication, dâ€™une interprÃ©tation et dâ€™un exemple pratique.

---

## 5.1 â€“ Exploration des donnÃ©es visuelles

### ğŸ¯ Pourquoi visualiser les donnÃ©es ?
La visualisation permet de :
- Comprendre rapidement les distributions.
- Identifier les tendances et valeurs aberrantes.
- Valider les hypothÃ¨ses avant de modÃ©liser.
- Communiquer efficacement les rÃ©sultats.

---

### ğŸ“Š Histogramme â€“ Distribution dâ€™une variable
![Histogramme](image/histogramme_ages.png)

- Montre la **rÃ©partition** dâ€™une variable numÃ©rique.  
- Exemple : lâ€™Ã¢ge des clients se concentre entre **25 et 35 ans** â†’ cible marketing jeune adulte.  

---

### ğŸ”µ Scatter Plot â€“ Relation entre deux variables
![Scatter Plot](image/scatter_taille_poids.JPG)

- Chaque point reprÃ©sente une observation (`taille` vs `poids`).  
- La **ligne rouge** montre la rÃ©gression linÃ©aire.  
- CorrÃ©lation forte : **r = 0.726**, RÂ² = 0.527.  
- ğŸ‘‰ Plus la taille augmente, plus le poids augmente.

---

### ğŸ“¦ Boxplot â€“ RÃ©sumÃ© statistique visuel
![Boxplot](image/boxplot.JPG)

- La **boÃ®te** contient 50 % des valeurs (Q1â€“Q3).  
- La ligne au centre = **mÃ©diane**.  
- Les **points isolÃ©s** = valeurs aberrantes.  
- Exemple : en IT, quelques salaires extrÃªmes dÃ©passent 120kâ‚¬.

---

### ğŸ“Š Graphique en barres â€“ Variables catÃ©gorielles
![Bar Chart](image/Graphique_barres.JPG)

- Montre les effectifs par catÃ©gorie.  
- Exemple : Paris concentre **26.9 % des clients**, Strasbourg seulement 7.5 %.  
- Utile pour analyser la **rÃ©partition gÃ©ographique**.

---

### ğŸŒ¡ï¸ Heatmap â€“ Matrice de corrÃ©lations
![Heatmap](image/matrice_correlation.JPG)

- Chaque case montre la **corrÃ©lation entre variables**.  
- Exemples :
  - `ExpÃ©rience` â†” `Salaire` : **0.952** (trÃ¨s forte corrÃ©lation positive).  
  - `Heures_travail` â†” `Satisfaction` : **corrÃ©lation nÃ©gative**.  
- ğŸ‘‰ Permet de dÃ©tecter les variables redondantes.

---

## 5.2 â€“ Graphiques spÃ©cialisÃ©s pour le Machine Learning

### ğŸŒ¸ Pairplot â€“ Relations multiples
![Pairplot â€“ Iris](image/relations-entre-toutes-les-variables-Pairplot-complet.JPG)

- Visualise **toutes les relations possibles** entre variables.  
- Les pÃ©tales (`petal length` et `petal width`) discriminent fortement les espÃ¨ces dâ€™Iris.  

---

### ğŸ· Feature Importance â€“ Variables clÃ©s
![Feature Importance](image/Feature_Importance_complete.JPG)

- Montre les variables qui contribuent le plus Ã  la classification.  
- Exemple vins :
  - **Flavanoids** (0.202) et **Color intensity** (0.171) dominent.  
- ğŸ‘‰ Quelques variables suffisent pour une bonne prÃ©diction.

---

### ğŸ» Violin Plot â€“ Distribution dÃ©taillÃ©e
![Violin Plot](image/violin-plot.JPG)

- Combine **boxplot + densitÃ©**.  
- Exemple : le Groupe C montre une **grande variabilitÃ©** avec des outliers > 150.  

---

### ğŸ”¢ Matrice de confusion â€“ Classification des chiffres
![Matrice de confusion](image/matrice-de-confusion.JPG)

- Ã‰value les performances de classification.  
- PrÃ©cision globale : **97.3 %**.  
- Erreurs rares et logiques (ex. `7` confondu avec `9`).  

---

### ğŸ“ˆ Courbes ROC â€“ Comparaison de modÃ¨les
![Courbes ROC](image/curbes-ROC.JPG)

- AUC (aire sous la courbe) :  
  - **SVM** = 0.989 â†’ meilleur modÃ¨le.  
  - Random Forest = 0.986, Logistic Regression = 0.982.  
- ğŸ‘‰ Tous excellents (AUC > 0.98).  

---

### ğŸ“š Courbes dâ€™apprentissage â€“ Random Forest
![Courbe dâ€™apprentissage](image/curbes-d-aprentisage-random-forest.JPG)

- Score entraÃ®nement = 1.000  
- Score validation = 0.961  
- Ã‰cart faible (0.039) â†’ modÃ¨le **Ã©quilibrÃ©, pas dâ€™overfitting**.  

---

### ğŸ“Š Analyse complÃ¨te des rÃ©sidus
![Analyse des rÃ©sidus](image/analyse-complete-de-residus.JPG)

- Les rÃ©sidus suivent une **distribution normale** (p-value = 0.85).  
- Pas de variance non constante â†’ **homoscÃ©dasticitÃ© respectÃ©e**.  
- RÂ² = 0.82 â†’ le modÃ¨le explique 82 % de la variance.  

---

## âœ… Points clÃ©s Ã  retenir

- Toujours **explorer visuellement** les donnÃ©es avant de modÃ©liser.  
- Les graphiques essentiels : histogramme, scatter, boxplot, bar chart.  
- Pour le ML : pairplot, feature importance, confusion matrix, ROC, learning curves, rÃ©sidus.  
- Une bonne visualisation permet de :  
  - DÃ©tecter problÃ¨mes tÃ´t.  
  - Valider les hypothÃ¨ses.  
  - Expliquer les rÃ©sultats clairement.  

ğŸ‘‰ **Un graphique clair vaut mieux quâ€™un tableau complexe !**





