# üìä 5.5 ‚Äì Dashboards interactifs
**Module 5 ‚Ä¢ Chapitre 5 ‚Ä¢ Niveau : D√©butant ‚Ä¢ Dur√©e : ~40-45 min**

## üéØ Objectif
Passer des graphiques statiques aux **dashboards dynamiques** pour explorer vos donn√©es et mod√®les en temps r√©el.

---

## üöÄ Ce que vous allez apprendre
- Introduction aux **dashboards interactifs**
- Utilisation de **Plotly** pour des graphiques dynamiques
- Cr√©ation d‚Äôapplications web simples avec **Streamlit**
- Exploration interactive avec les **widgets Jupyter**
- Construire un **dashboard ML complet**

---

## ‚ùì Pourquoi des dashboards interactifs ?
Les graphiques statiques ont leurs limites.  
L‚Äôinteractivit√© ajoute une nouvelle dimension :

> *"Un dashboard interactif vaut mille graphiques statiques"*

### ‚úÖ Avantages
- Exploration en temps r√©el  
- Filtrage dynamique des donn√©es  
- Zoom et navigation ais√©s  
- Mise √† jour automatique  
- Partage facile avec les √©quipes  

### üîé Cas d‚Äôusage typiques
- Monitoring de mod√®les en production  
- Exploration de datasets complexes  
- Pr√©sentation de r√©sultats √† des clients  
- Analyse collaborative  
- Prototypage rapide  

---
# üöÄ Introduction √† Streamlit

Streamlit est une biblioth√®que Python qui permet de transformer rapidement des scripts en **applications web interactives** pour la data science.

---

## ‚öôÔ∏è Installation

Assurez-vous d‚Äôavoir activ√© votre environnement virtuel (`(venv-dashboards)`).

```bash
pip install streamlit==1.28.1

```python
import plotly.express as px
import pandas as pd

# Exemple simple avec le dataset int√©gr√© "iris"
df = px.data.iris()

fig = px.scatter(
    df, 
    x="sepal_width", 
    y="sepal_length", 
    color="species", 
    size="petal_length",
    hover_data=["petal_width"]
)

fig.show()
```

## üìå Introduction √† Plotly ‚Äì Graphiques interactifs
### 1. Premiers pas avec Plotly
Objectif : **Cr√©er des graphiques interactifs** avec zoom, hover et filtres.

# üìä Ventes ‚Äì Graphiques interactifs (Plotly)

Ce document d√©crit et interpr√®te trois visualisations interactives des ventes par **r√©gion**, **mois** et **ann√©e**.

![Aper√ßu des 3 graphiques](image/Plotly-Graphiques-interactifs-de-base.JPG)

---

## 1) √âvolution des Ventes par R√©gion (courbes)

**Ce que montre le graphique**
- **Axes** : l‚Äôaxe X est la **date** (chronologie sur ~2 ans), l‚Äôaxe Y le **montant des ventes**.
- **Couleurs** : chaque couleur correspond √† une **r√©gion** (Nord, Sud, Est, Ouest).
- **Annotation** : un marqueur indique un **¬´ Pic de No√´l ¬ª**, typique des hausses de fin d‚Äôann√©e.

**Comment le lire**
- Identifie les **tendances** (croissance/d√©croissance g√©n√©rale par r√©gion).
- Rep√®re la **saisonnalit√©** (pics r√©currents, creux estivaux, f√™tes de fin d‚Äôann√©e).
- Compare la **volatilit√©** : une r√©gion tr√®s ¬´ jaggy ¬ª varie beaucoup semaine apr√®s semaine.

**Interactions utiles**
- **Survol** pour conna√Ætre la valeur pr√©cise √† une date donn√©e.
- **Zoom**/glisser pour te focaliser sur un trimestre.
- **Clic sur la l√©gende** pour isoler/masquer une r√©gion et comparer proprement.

**√Ä retenir**
- Pic marqu√© en d√©cembre (effet promotions/f√™tes).  
- Si une r√©gion s‚Äô√©carte durablement des autres, cela peut r√©v√©ler un **probl√®me d‚Äôoffre/logistique** ou au contraire une **opportunit√©** (campagne locale efficace).

---

## 2) Ventes par Mois et R√©gion ‚Äî *Animation par Ann√©e* (nuage de points)

**Ce que montre le graphique**
- **Axes** : X = **mois (1‚Äì12)**, Y = **ventes**.
- **Couleurs** : r√©gions.  
- **Animation** : un **curseur d‚Äôann√©e** permet de jouer/comparer les ann√©es.
- **Info-bulle** : d√©tail du **produit**, **r√©gion**, **ann√©e**, **mois**, **ventes**.

**Comment le lire**
- La **dispersion verticale** √† un mois donn√© montre la **variabilit√©** (ex. plusieurs produits/segments).
- La **position des points** par r√©gion r√©v√®le les **mois forts/faibles** localement (ex. Sud plus haut en √©t√©).
- L‚Äô**animation** permet de voir comment ces patterns **changent d‚Äôune ann√©e √† l‚Äôautre** (effet d‚Äôun nouveau catalogue, m√©t√©o, inflation, etc.).

**Interactions utiles**
- **Jouer la timeline** (‚ñ∂Ô∏é) pour observer l‚Äô√©volution globale.
- **Pause** sur une ann√©e pour analyser les √©carts r√©gionaux mois par mois.
- **S√©lection** d‚Äôune r√©gion via la l√©gende pour suivre sa courbe de saisonnalit√©.

**√Ä retenir**
- Id√©al pour rep√©rer des **mois cl√©s** par r√©gion et v√©rifier si ces pics sont **r√©currents** (saison) ou **ponctuels** (op√©ration).

---

## 3) Ventes Mensuelles par R√©gion (barres empil√©es)

**Ce que montre le graphique**
- **Barres empil√©es** : chaque mois (X) affiche un **total de ventes** (hauteur) et la **contribution de chaque r√©gion** (couleurs empil√©es).
- Lecture imm√©diate du **total mensuel** et de la **part relative** des r√©gions.

**Comment le lire**
- La **hauteur totale** = performance globale du mois (rep√®re les meilleurs/pires mois).
- La **taille du segment** par r√©gion = **part de march√© relative** ce mois-l√†.
- Les **changements de composition** (ex. une r√©gion prend plus de place) signalent un **d√©placement de la demande**.

**Interactions utiles**
- **Clic sur la l√©gende** pour masquer/afficher une r√©gion ‚Üí recalcul visuel des parts.
- **Survol** pour lire la valeur exacte par r√©gion et le total du mois.

**√Ä retenir**
- Graphique parfait pour suivre la **contribution r√©gionale** au **P&L mensuel** et d√©tecter des **gains/pertes de part**.

---

## Synth√®se & pistes d‚Äôanalyse

- **Saisonnalit√© forte** confirm√©e par la courbe (pic de No√´l) et les points concentr√©s en fin d‚Äôann√©e.  
- **H√©t√©rog√©n√©it√© r√©gionale** : le nuage de points + l‚Äôempil√© mensuel montrent quelles r√©gions sur- ou sous-performent selon les mois.  
- **Actionnables** :
  - Ajuster les **stocks** et **promos** avant les pics (Q4).
  - D√©ployer des **campagnes cibl√©es** l√† o√π la part r√©gionale recule.
  - V√©rifier l‚Äô**effet produit** (info-bulle) : un produit tire-t-il une r√©gion particuli√®re ?

---

## Astuces d‚Äôusage (Plotly)

- **Zoom** et **pan** pour inspecter un intervalle pr√©cis.  
- **D√©sactiver** des s√©ries via la l√©gende pour comparer proprement.  
- **Exporter** : bouton **camera** pour enregistrer un PNG, ou exporter l‚ÄôHTML du graphique pour partage.

#2. Dashboard avec Plotly Dash
##Objectif : Cr√©er une application web compl√®te avec graphiques interactifs

# üßë‚Äçüíº Dashboard RH Interactif

Ce tableau de bord interactif permet d‚Äôanalyser les **donn√©es des employ√©s** par d√©partement, √¢ge, exp√©rience et performance.  
Il est construit avec **Dash/Plotly** et propose plusieurs filtres pour une exploration dynamique.

![Dashboard RH Interactif](image/dashbord-interactivo.JPG)

---

## 1Ô∏è‚É£ Indicateurs principaux (KPI)

En haut de l‚Äô√©cran, trois indicateurs r√©sument la population filtr√©e :

- **1 999 Employ√©s** ‚Üí effectif total analys√©.  
- **96 525 ‚Ç¨ Salaire Moyen** ‚Üí r√©mun√©ration moyenne sur l‚Äô√©chantillon.  
- **74,2/100 Performance Moyenne** ‚Üí score de performance global.  
- **7,0/10 Satisfaction Moyenne** ‚Üí note moyenne de satisfaction des employ√©s.

üí° Ces KPI changent selon les filtres (d√©partement, plage d‚Äôexp√©rience).

---

## 2Ô∏è‚É£ Distribution des Salaires (Histogramme empil√©)

**Description**
- Axe X : montant du **salaire**.  
- Axe Y : **effectif** (nombre d‚Äôemploy√©s).  
- Couleurs : d√©partements (HR, Finance, Marketing, Sales, IT).  

**Analyse**
- La courbe montre une distribution proche d‚Äôune **loi normale** (pic autour de 100 000 ‚Ç¨).  
- Chaque couleur montre la **r√©partition par d√©partement** ‚Üí certains d√©partements ont plus de salari√©s dans les tranches hautes/basses.

**Utilit√©**
- Rep√©rer des **√©carts de r√©mun√©ration** entre d√©partements.  
- D√©tecter des anomalies (trop d‚Äôemploy√©s tr√®s bas ou tr√®s hauts salaires).

---

## 3Ô∏è‚É£ Performance vs Salaire (Nuage de points)

**Description**
- Axe X : **score de performance** (0‚Äì100).  
- Axe Y : **salaire**.  
- Chaque point = un employ√©, color√© par d√©partement.

**Analyse**
- La dispersion montre qu‚Äôun **meilleur score de performance** est globalement associ√© √† un **salaire plus √©lev√©**.  
- Toutefois, il existe de la **variabilit√©** (certains employ√©s tr√®s performants mais peu pay√©s ‚Üí opportunit√© d‚Äôajustement RH).  
- Les nuages par couleur permettent de comparer les d√©partements (ex. IT vs Sales).

**Utilit√©**
- V√©rifier la **corr√©lation performance ‚Üî salaire**.  
- Identifier des **√©carts de traitement** √† poste √©quivalent.

---

## 4Ô∏è‚É£ Performance Moyenne par D√©partement (Barres avec intervalles de confiance)

**Description**
- Chaque barre = un d√©partement.  
- Hauteur = **moyenne des scores de performance**.  
- Barres verticales = **intervalle de confiance** (variabilit√© intra-d√©partement).

**Analyse**
- Permet de comparer les **d√©partements entre eux**.  
- Ex. si Marketing < IT ‚Üí potentiel besoin de **formations cibl√©es**.  
- Un intervalle de confiance large = performance tr√®s h√©t√©rog√®ne dans ce d√©partement.

**Utilit√©**
- Orienter les politiques de **formation** et d‚Äô**encadrement**.  
- D√©finir des objectifs r√©alistes selon la distribution interne.

---

## 5Ô∏è‚É£ Satisfaction par √Çge et Exp√©rience (Heatmap)

**Description**
- Axe X : **exp√©rience (ann√©es)** ‚Üí 0‚Äì5, 5‚Äì10, 10‚Äì20, 20‚Äì30, 30+.  
- Axe Y : **tranche d‚Äô√¢ge** ‚Üí 20‚Äì25, 25‚Äì30, ‚Ä¶, 45‚Äì55.  
- Couleurs = **note moyenne de satisfaction** (0‚Äì10).  

**Analyse**
- Les cases montrent les combinaisons √¢ge/exp√©rience.  
- Ex. forte satisfaction chez les **employ√©s exp√©riment√©s (30+ ans d‚Äôexp.)** et certains jeunes profils.  
- Des zones plus rouges indiquent des tranches **moins satisfaites** (ex. 30‚Äì35 ans avec 20‚Äì30 ans d‚Äôexp√©rience).

**Utilit√©**
- Identifier des **populations √† risque de turnover**.  
- Ajuster des politiques RH selon la **carri√®re** (mentorat, mobilit√© interne, reconnaissance salariale).

---

## 6Ô∏è‚É£ Filtres interactifs

En haut du dashboard :
- **S√©lecteur de d√©partement** ‚Üí pour isoler HR, IT, Sales, etc.  
- **Plage d‚Äôexp√©rience (slider)** ‚Üí permet de comparer juniors vs seniors.  

üí° Ces filtres mettent √† jour **tous les graphiques** et les KPI.

---

## üéØ Synth√®se

- Les **salaires** suivent une distribution normale avec quelques √©carts selon les d√©partements.  
- La **corr√©lation performance ‚Üî salaire** existe mais n‚Äôest pas parfaite ‚Üí ajustements RH possibles.  
- La **satisfaction** varie fortement selon l‚Äô√¢ge et l‚Äôexp√©rience ‚Üí point crucial pour la r√©tention des talents.  
- Le dashboard permet aux RH de **cibler les actions** (formations, augmentations, politiques de motivation).

---

# üß™Streamlit - Applications ML interactives
##1. Application Streamlit compl√®te
##Objectif : Cr√©er une application web pour explorer des mod√®les ML

Cet outil Streamlit permet d‚Äôexplorer rapidement plusieurs **datasets classiques** (Iris, Vin, Breast Cancer), de **tester un mod√®le** (ex. SVM, Random Forest), d‚Äôajuster les **hyperparam√®tres**, et de visualiser **m√©triques, rapports et distributions** ‚Äî le tout en temps r√©el.

![Aper√ßu de l‚Äôapplication](image/5.5-Streamlit-Applications-ML-interactives.JPG)

# ü§ñ Explorateur de Mod√®les Machine Learning

Ce dashboard interactif permet d‚Äôexplorer diff√©rents mod√®les de classification sur des jeux de donn√©es standards (Iris, Wine, Breast Cancer).  
Il fournit une interface intuitive pour s√©lectionner un dataset, ajuster les hyperparam√®tres et visualiser les performances.

---

## üéõÔ∏è Panneau de Param√®tres (√† gauche)

- **Choisir un dataset** : liste d√©roulante permettant de s√©lectionner un jeu de donn√©es :
  - *Iris* : classification de fleurs
  - *Wine* : caract√©ristiques de vins
  - *Breast Cancer* : d√©tection de tumeurs b√©nignes ou malignes  

- **Kernel** : choix de la fonction noyau (ici `rbf`) pour un mod√®le SVM.  

- **Taille du test (%)** : curseur d√©finissant la proportion des donn√©es r√©serv√©es au test (ici 20%).  

- **Instructions** : rappels √©tape par √©tape pour utiliser l‚Äôexplorateur :
  1. Choisissez un dataset  
  2. S√©lectionnez un mod√®le et ajustez ses param√®tres  
  3. Explorez les onglets d‚Äôanalyses  
  4. Modifiez les param√®tres et observez l‚Äôimpact en temps r√©el  

- **Conseils** :  
  - Commencez avec Random Forest (plus stable)  
  - Augmentez progressivement la complexit√©  
  - Observez l‚Äôimpact des hyperparam√®tres  

---

## üìä Indicateurs de Performance (en haut)

- **Pr√©cision** : 0.947 (94,7% d‚Äôexactitude globale du mod√®le).  
- **√âchantillons Train** : 455 donn√©es utilis√©es pour l‚Äôentra√Ænement.  
- **√âchantillons Test** : 114 donn√©es r√©serv√©es pour l‚Äô√©valuation.  
- **Features** : 30 variables explicatives utilis√©es par le mod√®le.  

Ces indicateurs donnent une vue synth√©tique de la robustesse du mod√®le entra√Æn√©.

---

## üìë Rapport D√©tail√© (onglet s√©lectionn√©)

### Rapport de Classification
Tableau affichant les principales m√©triques pour chaque classe :

| Classe      | Precision | Recall | F1-Score | Support |
|-------------|-----------|--------|----------|---------|
| **malignant** | 0.922     | 1.000  | 0.86     | 43      |
| **benign**    | 1.000     | 0.959  | 0.98     | 71      |
| **accuracy**  | -         | -      | 0.947    | 114     |
| **macro avg** | 0.961     | 0.930  | 0.93     | 114     |
| **weighted avg** | 0.951 | 0.947  | 0.94     | 114     |

- **Precision** : proportion de pr√©dictions correctes parmi celles donn√©es par le mod√®le.  
- **Recall** : proportion d‚Äô√©l√©ments correctement identifi√©s parmi la classe r√©elle.  
- **F1-Score** : moyenne harmonique de precision et recall (√©quilibre).  
- **Support** : nombre d‚Äô√©chantillons par classe.  

‚û°Ô∏è R√©sultat : le mod√®le est particuli√®rement performant pour d√©tecter les cas b√©nins, tout en restant tr√®s bon pour les cas malins.

---

### Informations du Dataset

- **Nombre total d‚Äô√©chantillons** : 569  
- **Nombre de features** : 30  
- **Nombre de classes** : 2 (*malignant* et *benign*)  
- **√âchantillons d‚Äôentra√Ænement** : 455  
- **√âchantillons de test** : 114  

#### Distribution des classes
- **Malignant** : 212 (37,3%)  
- **Benign** : 357 (62,7%)  

‚û°Ô∏è Les classes sont l√©g√®rement d√©s√©quilibr√©es (plus de cas b√©nins que malins), ce qui peut influencer le recall.

---

## üéØ Interpr√©tation Globale

- Le mod√®le atteint une pr√©cision √©lev√©e (**94,7%**), adapt√©e pour une t√¢che m√©dicale sensible.  
- Les m√©triques montrent un bon compromis entre **rappel** (ne pas manquer de cas malins) et **pr√©cision** (√©viter les faux positifs).  
- La r√©partition train/test est √©quilibr√©e, garantissant une √©valuation fiable.  

üëâ Ce type de dashboard permet aux Data Scientists et praticiens de **tester rapidement diff√©rents mod√®les et configurations** pour observer leur impact sur la performance.


---

# üìä Dashboard de Monitoring ‚Äì Analyse D√©taill√©e


![Aper√ßu de l‚Äôapplication](image/5.5-monitoring-ML-dashborad-2.JPG)


Ce dashboard illustre un syst√®me de **surveillance en temps r√©el** des mod√®les de Machine Learning. Il est compos√© de plusieurs sections qui fournissent des informations sur l‚Äô√©tat du syst√®me, la d√©rive des donn√©es et les performances op√©rationnelles.

---

## üîî Alertes Automatiques

- **Barre verte** : indique que *tous les indicateurs sont dans les normes*.  
- Cela signifie qu‚Äôaucun seuil critique n‚Äôa √©t√© d√©pass√© (pr√©cision, latence, m√©moire, etc.).  
- Le bouton **¬´ Rafra√Æchir les Donn√©es ¬ª** permet de mettre √† jour les graphiques et les m√©triques en direct.

---

## üìà Analyse de D√©rive des Donn√©es

Cette partie mesure la **stabilit√© des donn√©es d‚Äôentr√©e** utilis√©es par le mod√®le.  
Une d√©rive trop importante peut indiquer que les donn√©es de production ne ressemblent plus aux donn√©es d‚Äôentra√Ænement, ce qui risque de r√©duire la performance du mod√®le.

### Graphiques √† gauche ‚Äì *Moyenne des features*
- **Feature 1 ‚Äì Moyenne (ligne bleue)** : montre l‚Äô√©volution de la valeur moyenne de la premi√®re variable explicative.  
  - Ici, la moyenne reste relativement stable avec une l√©g√®re tendance haussi√®re.  
- **Feature 2 ‚Äì Moyenne (ligne rouge)** : suit la moyenne de la deuxi√®me variable.  
  - On observe des fluctuations mais elle reste proche de z√©ro, ce qui est acceptable.  

‚û°Ô∏è Ces courbes permettent de d√©tecter un √©ventuel *shift de distribution*.

### Graphiques √† droite ‚Äì *√âcart-type des features*
- **Feature 1 ‚Äì √âcart-type (bleu)** : mesure la variabilit√© des donn√©es pour la Feature 1.  
  - On observe des oscillations normales, signe d‚Äôune variabilit√© stable.  
- **Feature 2 ‚Äì √âcart-type (rouge)** : suit la dispersion de la Feature 2.  
  - Ici aussi, les variations sont r√©guli√®res, aucune d√©rive anormale d√©tect√©e.  

‚û°Ô∏è Une hausse brutale de l‚Äô√©cart-type signalerait une instabilit√© dans les donn√©es.

---

## üìä R√©sum√© du Monitoring

Ce tableau pr√©sente les **indicateurs cl√©s du mod√®le et du syst√®me**, compar√©s aux seuils attendus.

| M√©trique   | Valeur Actuelle | Seuil | Statut | Interpr√©tation |
|------------|----------------|-------|--------|----------------|
| **Accuracy** | 0.910 | 0.900 | ‚úÖ OK | Le mod√®le conserve une pr√©cision au-dessus du seuil critique. |
| **Latence** | 65 ms | 100 ms | ‚úÖ OK | Les pr√©dictions sont rapides, en dessous de la limite fix√©e. |
| **Volume** | 1,511 | N/A | ‚úÖ N/A | Nombre d‚Äô√©chantillons trait√©s, indicatif de la charge du syst√®me. |
| **Erreurs** | 4.9% | 10% | ‚úÖ OK | Taux d‚Äôerreurs reste sous contr√¥le. |
| **M√©moire** | 2.7 GB | 4.0 GB | ‚úÖ OK | La consommation m√©moire est dans la limite autoris√©e. |
| **CPU** | 56% | 80% | ‚úÖ OK | L‚Äôutilisation du processeur reste mod√©r√©e. |

---

## üéØ Interpr√©tation Globale

- ‚úÖ Tous les indicateurs sont **dans le vert** : le syst√®me est stable.  
- üìâ Aucune d√©rive majeure d√©tect√©e sur les features surveill√©es.  
- üö¶ Le tableau de monitoring montre une **marge de s√©curit√© confortable** (accuracy > seuil, latence < limite, m√©moire < seuil).  

En r√©sum√©, le mod√®le est **op√©rationnel et fiable** dans ce contexte de monitoring continu.

------


![Aper√ßu de l‚Äôapplication](image/5.5-monitoring-ML-dashborad.JPG)


# üìä Dashboard de Monitoring ML ‚Äî Explication d√©taill√©e

Ce tableau de bord suit en continu la **sant√© d‚Äôun mod√®le de Machine Learning** et de son **infrastructure**.  
Il se compose de 3 zones : **M√©triques en Temps R√©el**, **Tendances de Performance**, et **Ressources Syst√®me**.

![Aper√ßu](images/5.5-monitoring-ML-dashborad.JPG)

---

## 1) üü¢ M√©triques en Temps R√©el (cartes KPI)

- **Accuracy : 0.910**  
  Proportion des pr√©dictions correctes sur la fen√™tre d‚Äôobservation r√©cente.  
  > Interpr√©tation : au-dessus du seuil de 0.90 ‚Üí **OK** (mod√®le globalement fiable).

- **Latence (ms) : 65**  
  Temps moyen pour retourner une pr√©diction (du `request_in` √† `response_out`).  
  > Interpr√©tation : inf√©rieur au seuil de 100 ms ‚Üí **OK** (service r√©actif).

- **Pr√©dictions/jour : 1 511**  
  Volume trait√© sur 24h. Sert √† d√©tecter des changements de trafic (pics/sous-charge).  
  > Interpr√©tation : volume stable ‚Üí **OK** (charge r√©guli√®re).

- **Taux d‚ÄôErreur : 4.8%**  
  Part des requ√™tes en √©chec (exceptions, timeouts) **ou** des pr√©dictions explicitement invalid√©es par des r√®gles m√©tiers.  
  > Interpr√©tation : sous le seuil critique de 10% ‚Üí **OK**.

**√Ä retenir** : les quatre KPI sont **dans le vert**. Aucune alerte imm√©diate.

---

## 2) üìà Tendances de Performance (s√©ries temporelles)

### 2.1 √âvolution de la Pr√©cision du Mod√®le (ligne)
- **Ce que l‚Äôon voit** : la pr√©cision quotidienne (ou par cr√©neau horaire) avec une **ligne de seuil d‚Äôalarme √† 0.90** (pointill√©s rouges).  
- **Comment lire** : la courbe reste au-dessus du seuil, avec de l√©g√®res oscillations.  
- **Ce que √ßa implique** : **pas de d√©rive de performance** significative. Les variations normales peuvent venir du mix utilisateurs, des versions de donn√©es, ou de la saisonnalit√©.

**Actions si anomalie**  
- Si la pr√©cision passe **sous 0.90** de mani√®re persistante :  
  1) v√©rifier les **donn√©es d‚Äôentr√©e** (sch√©ma, encodage, features manquantes),  
  2) comparer les distributions production vs entra√Ænement (**d√©rive**),  
  3) r√©√©valuer le **seuil de d√©cision** ou relancer un **r√©entra√Ænement**.

---

### 2.2 √âvolution de la Latence (ligne)
- **Ce que l‚Äôon voit** : la latence moyenne avec une **ligne d‚Äôalerte ~80‚Äì100 ms** (pointill√©s jaunes/oranges selon l‚Äôimpl√©mentation).  
- **Observation** : une ou deux **pointes** (spikes) ponctuelles, sinon la plupart des points **< 80 ms**.  
- **Interpr√©tation** : service **globalement fluide** ; les pics pourraient correspondre √† des **pics de charge**, **GC**, ou une **d√©pendance externe** lente.

**Actions si anomalie**  
- Si des pics se multiplient :  
  - activer un suivi **p95/p99** (latence queue),  
  - **cache** sur features ou sorties souvent r√©utilis√©es,  
  - profiling (CPU/GPU), connection pooling, **autoscaling**.

---

### 2.3 Volume de Pr√©dictions par Jour (barres)
- **Ce que l‚Äôon voit** : barres quasi constantes autour de **1 500 pr√©dictions/jour**.  
- **Interpr√©tation** : trafic **stable** ‚Üí id√©al pour comparer les performances √† p√©rim√®tre constant.  
- **Utilit√©** : un **effondrement** ou une **explosion** du volume peut expliquer des changements de latence/erreurs (ex. afflux marketing, incident amont/aval).

---

### 2.4 √âvolution du Taux d‚ÄôErreur (ligne)
- **Ce que l‚Äôon voit** : ligne avec **seuil critique √† 10%** (pointill√©s rouges).  
- **Observation** : oscillations dans une plage **3‚Äì8%**, quelques cr√™tes mais **sous 10%**.  
- **Interpr√©tation** : erreurs **contenues** ; surveiller les mont√©es corr√©l√©es (ex. hausse latence + erreurs = saturation).

**Actions si anomalie**  
- Si > 10% ou croissance continue :  
  - inspecter logs/trace **par code d‚Äôerreur** (timeout, 5xx, validation),  
  - v√©rifier **versions** (mod√®le, feature store, sch√©mas),  
  - mettre en place **circuit breaker** et **retries**.

---

## 3) üñ•Ô∏è Ressources Syst√®me

### 3.1 Utilisation M√©moire (GB) ‚Äî avec **Limite 4 GB**
- **Ce que l‚Äôon voit** : tendance globale **montante mais sous 4 GB**.  
- **Interpr√©tation** : pas de fuite √©vidente. Les **micro-spikes** peuvent √™tre li√©s aux batchs ou au chargement de mod√®les.

**Actions si anomalie**  
- Si d√©passements fr√©quents de la **limite 4 GB** :  
  - charger le mod√®le **une seule fois** (singleton),  
  - lib√©rer les buffers temporaires,  
  - r√©duire la **taille de batch**,  
  - activer une **limitation de concurrence** (workers).

---

### 3.2 Utilisation CPU (%) ‚Äî **Seuil d‚Äôalerte ~80%**
- **Ce que l‚Äôon voit** : une **grosse mont√©e** initiale, puis une stabilisation **< 60%** la plupart du temps, avec quelques oscillations.  
- **Interpr√©tation** : capacit√© **disponible** ; les pics peuvent co√Øncider avec des recalculs, un **autoscaling** ou le **warm-up**.

**Actions si anomalie**  
- Si > 80% de fa√ßon persistante :  
  - augmenter le **replica count** / autoscaler,  
  - profiler le code (vectorisation, I/O),  
  - √©purer les pr√©/post-traitements lour


# ‚úÖ Bonnes pratiques pour les dashboards

## üé® Design UX
| Bonnes pratiques | Explication |
|------------------|-------------|
| Interface intuitive et claire | Un design √©pur√© facilite la compr√©hension imm√©diate. |
| Temps de chargement rapide | Les utilisateurs n‚Äôattendent pas ‚Üí meilleure exp√©rience. |
| Responsive design | Le tableau de bord s‚Äôadapte aux √©crans (desktop, tablette, mobile). |
| Navigation facile | Acc√®s rapide aux sections ‚Üí gain de temps. |
| Feedback visuel imm√©diat | L‚Äôutilisateur re√ßoit une confirmation ou un retour instantan√© (ex. chargement, mise √† jour). |

---

## ‚ö° Performance
| Bonnes pratiques | Explication |
|------------------|-------------|
| Cache des donn√©es co√ªteuses | √âvite de recalculer sans cesse les m√™mes requ√™tes lourdes. |
| Pagination pour gros datasets | Am√©liore la vitesse en affichant par lot. |
| Chargement asynchrone | Permet de charger certaines parties sans bloquer tout le dashboard. |
| Optimisation des requ√™tes | R√©duit le temps de r√©ponse c√¥t√© base de donn√©es/API. |
| Compression des donn√©es | Acc√©l√®re le transfert entre serveur et client. |

---

## üîß Maintenance
| Bonnes pratiques | Explication |
|------------------|-------------|
| Code modulaire et r√©utilisable | Favorise la maintenabilit√© et r√©duit les duplications. |
| Configuration externalis√©e | Param√®tres g√©r√©s hors du code (fichiers `.env`, `.yaml`). |
| Logging et monitoring | Suivi des erreurs et performances pour anticiper les pannes. |
| Tests automatis√©s | Garantissent la fiabilit√© lors des mises √† jour. |
| Documentation utilisateur | Facilite la prise en main par d‚Äôautres personnes. |

---

# üõ†Ô∏è Outils et technologies recommand√©s

| Outil             | Type                        | Avantages                                   | Cas d‚Äôusage                                |
|-------------------|-----------------------------|---------------------------------------------|--------------------------------------------|
| **Plotly**        | Graphiques interactifs      | Riche, interactif, pr√™t pour le web         | Graphiques complexes, export web           |
| **Streamlit**     | Application web             | Simple, rapide, Python pur                  | Prototypes, d√©monstrations                 |
| **Dash**          | Dashboard web               | Tr√®s personnalisable, robuste               | Applications de production                 |
| **Jupyter Widgets** | Notebooks interactifs     | Int√©gr√© √† Jupyter, exploration rapide       | Recherche, prototypage                     |
| **Bokeh**         | Visualisation web           | Haute performance, big data                 | Grandes datasets, temps r√©el               |

---

üìå **Conseil pratique** :  
Commencez par **Streamlit** pour prototyper rapidement, utilisez **Plotly** pour les graphiques avanc√©s, et migrez vers **Dash** pour une mise en production robuste.  
Pour la recherche exploratoire ‚Üí **Jupyter Widgets**, et pour les tr√®s gros volumes de donn√©es ‚Üí **Bokeh**.

# üöÄ Exercice Pratique Guid√© ‚Äî Cr√©ez votre premier Dashboard

üëâ Suivez ces **7 √©tapes** pour construire un dashboard interactif de A √† Z :

---

## üìã √âtapes √† suivre

1Ô∏è‚É£ **Pr√©paration** üõ†Ô∏è  
Cr√©ez l‚Äôenvironnement virtuel et installez les d√©pendances n√©cessaires.

2Ô∏è‚É£ **Dataset** üìä  
Choisissez un dataset qui vous int√©resse (Iris, Titanic, ou vos propres donn√©es).

3Ô∏è‚É£ **Graphiques** üìà  
Cr√©ez 3-4 graphiques **Plotly interactifs** dans le dossier `scripts/`.

4Ô∏è‚É£ **Application** üíª  
D√©veloppez une application **Streamlit** dans le dossier `streamlit_apps/`.

5Ô∏è‚É£ **Interactivit√©** üéõÔ∏è  
Ajoutez des filtres et des contr√¥les utilisateurs pour enrichir l‚Äôexp√©rience.

6Ô∏è‚É£ **Test** ‚úÖ  
Lancez l‚Äôapplication et v√©rifiez que toutes les fonctionnalit√©s marchent.

7Ô∏è‚É£ **Partage** ü§ù  
Montrez vos dashboards √† des coll√®gues et collectez leurs retours pour am√©liorer.

---

## ‚úÖ Checklist de validation

### üåç Environnement
- ‚úîÔ∏è Environnement virtuel cr√©√© et activ√©  
- ‚úîÔ∏è Toutes les d√©pendances install√©es  
- ‚úîÔ∏è Script de test ex√©cut√© avec succ√®s  
- ‚úîÔ∏è Structure de projet cr√©√©e  
- ‚úîÔ∏è `requirements.txt` g√©n√©r√©  

### üì¶ Applications
- ‚úîÔ∏è Dashboard **Streamlit** fonctionnel  
- ‚úîÔ∏è Application **Dash** test√©e  
- ‚úîÔ∏è Widgets **Jupyter** op√©rationnels  
- ‚úîÔ∏è Graphiques **Plotly** interactifs  
- ‚úîÔ∏è Monitoring dashboard cr√©√©  

---

‚ú® **Astuce bonus :**  
N‚Äôayez pas peur de tester plusieurs datasets et de varier les graphiques (histogrammes, heatmaps, barres empil√©es, s√©ries temporelles).  
Un bon dashboard = **clart√© + interactivit√© + esth√©tique** üé®

-------------


![Aper√ßu](images/test-rapide.JPG)


---------------
