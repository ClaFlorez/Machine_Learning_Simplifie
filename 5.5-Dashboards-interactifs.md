# ğŸ“Š 5.5 â€“ Dashboards interactifs
**Module 5 â€¢ Chapitre 5 â€¢ Niveau : DÃ©butant â€¢ DurÃ©e : ~40-45 min**

## ğŸ¯ Objectif
Passer des graphiques statiques aux **dashboards dynamiques** pour explorer vos donnÃ©es et modÃ¨les en temps rÃ©el.

---

## ğŸš€ Ce que vous allez apprendre
- Introduction aux **dashboards interactifs**
- Utilisation de **Plotly** pour des graphiques dynamiques
- CrÃ©ation dâ€™applications web simples avec **Streamlit**
- Exploration interactive avec les **widgets Jupyter**
- Construire un **dashboard ML complet**

---

## â“ Pourquoi des dashboards interactifs ?
Les graphiques statiques ont leurs limites.  
Lâ€™interactivitÃ© ajoute une nouvelle dimension :

> *"Un dashboard interactif vaut mille graphiques statiques"*

### âœ… Avantages
- Exploration en temps rÃ©el  
- Filtrage dynamique des donnÃ©es  
- Zoom et navigation aisÃ©s  
- Mise Ã  jour automatique  
- Partage facile avec les Ã©quipes  

### ğŸ” Cas dâ€™usage typiques
- Monitoring de modÃ¨les en production  
- Exploration de datasets complexes  
- PrÃ©sentation de rÃ©sultats Ã  des clients  
- Analyse collaborative  
- Prototypage rapide  

---
# ğŸš€ Introduction Ã  Streamlit

Streamlit est une bibliothÃ¨que Python qui permet de transformer rapidement des scripts en **applications web interactives** pour la data science.

---

## âš™ï¸ Installation

Assurez-vous dâ€™avoir activÃ© votre environnement virtuel (`(venv-dashboards)`).

```bash
pip install streamlit==1.28.1

```python
import plotly.express as px
import pandas as pd

# Exemple simple avec le dataset intÃ©grÃ© "iris"
df = px.data.iris()

fig = px.scatter(
    df, 
    x="sepal_width", 
    y="sepal_length", 
    color="species", 
    size="petal_length",
    hover_data=["petal_width"]
)

fig.show()
```

## ğŸ“Œ Introduction Ã  Plotly â€“ Graphiques interactifs
### 1. Premiers pas avec Plotly
Objectif : **CrÃ©er des graphiques interactifs** avec zoom, hover et filtres.

# ğŸ“Š Ventes â€“ Graphiques interactifs (Plotly)

Ce document dÃ©crit et interprÃ¨te trois visualisations interactives des ventes par **rÃ©gion**, **mois** et **annÃ©e**.

![AperÃ§u des 3 graphiques](image/Plotly-Graphiques-interactifs-de-base.JPG)

---

## 1) Ã‰volution des Ventes par RÃ©gion (courbes)

**Ce que montre le graphique**
- **Axes** : lâ€™axe X est la **date** (chronologie sur ~2 ans), lâ€™axe Y le **montant des ventes**.
- **Couleurs** : chaque couleur correspond Ã  une **rÃ©gion** (Nord, Sud, Est, Ouest).
- **Annotation** : un marqueur indique un **Â« Pic de NoÃ«l Â»**, typique des hausses de fin dâ€™annÃ©e.

**Comment le lire**
- Identifie les **tendances** (croissance/dÃ©croissance gÃ©nÃ©rale par rÃ©gion).
- RepÃ¨re la **saisonnalitÃ©** (pics rÃ©currents, creux estivaux, fÃªtes de fin dâ€™annÃ©e).
- Compare la **volatilitÃ©** : une rÃ©gion trÃ¨s Â« jaggy Â» varie beaucoup semaine aprÃ¨s semaine.

**Interactions utiles**
- **Survol** pour connaÃ®tre la valeur prÃ©cise Ã  une date donnÃ©e.
- **Zoom**/glisser pour te focaliser sur un trimestre.
- **Clic sur la lÃ©gende** pour isoler/masquer une rÃ©gion et comparer proprement.

**Ã€ retenir**
- Pic marquÃ© en dÃ©cembre (effet promotions/fÃªtes).  
- Si une rÃ©gion sâ€™Ã©carte durablement des autres, cela peut rÃ©vÃ©ler un **problÃ¨me dâ€™offre/logistique** ou au contraire une **opportunitÃ©** (campagne locale efficace).

---

## 2) Ventes par Mois et RÃ©gion â€” *Animation par AnnÃ©e* (nuage de points)

**Ce que montre le graphique**
- **Axes** : X = **mois (1â€“12)**, Y = **ventes**.
- **Couleurs** : rÃ©gions.  
- **Animation** : un **curseur dâ€™annÃ©e** permet de jouer/comparer les annÃ©es.
- **Info-bulle** : dÃ©tail du **produit**, **rÃ©gion**, **annÃ©e**, **mois**, **ventes**.

**Comment le lire**
- La **dispersion verticale** Ã  un mois donnÃ© montre la **variabilitÃ©** (ex. plusieurs produits/segments).
- La **position des points** par rÃ©gion rÃ©vÃ¨le les **mois forts/faibles** localement (ex. Sud plus haut en Ã©tÃ©).
- Lâ€™**animation** permet de voir comment ces patterns **changent dâ€™une annÃ©e Ã  lâ€™autre** (effet dâ€™un nouveau catalogue, mÃ©tÃ©o, inflation, etc.).

**Interactions utiles**
- **Jouer la timeline** (â–¶ï¸) pour observer lâ€™Ã©volution globale.
- **Pause** sur une annÃ©e pour analyser les Ã©carts rÃ©gionaux mois par mois.
- **SÃ©lection** dâ€™une rÃ©gion via la lÃ©gende pour suivre sa courbe de saisonnalitÃ©.

**Ã€ retenir**
- IdÃ©al pour repÃ©rer des **mois clÃ©s** par rÃ©gion et vÃ©rifier si ces pics sont **rÃ©currents** (saison) ou **ponctuels** (opÃ©ration).

---

## 3) Ventes Mensuelles par RÃ©gion (barres empilÃ©es)

**Ce que montre le graphique**
- **Barres empilÃ©es** : chaque mois (X) affiche un **total de ventes** (hauteur) et la **contribution de chaque rÃ©gion** (couleurs empilÃ©es).
- Lecture immÃ©diate du **total mensuel** et de la **part relative** des rÃ©gions.

**Comment le lire**
- La **hauteur totale** = performance globale du mois (repÃ¨re les meilleurs/pires mois).
- La **taille du segment** par rÃ©gion = **part de marchÃ© relative** ce mois-lÃ .
- Les **changements de composition** (ex. une rÃ©gion prend plus de place) signalent un **dÃ©placement de la demande**.

**Interactions utiles**
- **Clic sur la lÃ©gende** pour masquer/afficher une rÃ©gion â†’ recalcul visuel des parts.
- **Survol** pour lire la valeur exacte par rÃ©gion et le total du mois.

**Ã€ retenir**
- Graphique parfait pour suivre la **contribution rÃ©gionale** au **P&L mensuel** et dÃ©tecter des **gains/pertes de part**.

---

## SynthÃ¨se & pistes dâ€™analyse

- **SaisonnalitÃ© forte** confirmÃ©e par la courbe (pic de NoÃ«l) et les points concentrÃ©s en fin dâ€™annÃ©e.  
- **HÃ©tÃ©rogÃ©nÃ©itÃ© rÃ©gionale** : le nuage de points + lâ€™empilÃ© mensuel montrent quelles rÃ©gions sur- ou sous-performent selon les mois.  
- **Actionnables** :
  - Ajuster les **stocks** et **promos** avant les pics (Q4).
  - DÃ©ployer des **campagnes ciblÃ©es** lÃ  oÃ¹ la part rÃ©gionale recule.
  - VÃ©rifier lâ€™**effet produit** (info-bulle) : un produit tire-t-il une rÃ©gion particuliÃ¨re ?

---

## Astuces dâ€™usage (Plotly)

- **Zoom** et **pan** pour inspecter un intervalle prÃ©cis.  
- **DÃ©sactiver** des sÃ©ries via la lÃ©gende pour comparer proprement.  
- **Exporter** : bouton **camera** pour enregistrer un PNG, ou exporter lâ€™HTML du graphique pour partage.

#2. Dashboard avec Plotly Dash
##Objectif : CrÃ©er une application web complÃ¨te avec graphiques interactifs

# ğŸ§‘â€ğŸ’¼ Dashboard RH Interactif

Ce tableau de bord interactif permet dâ€™analyser les **donnÃ©es des employÃ©s** par dÃ©partement, Ã¢ge, expÃ©rience et performance.  
Il est construit avec **Dash/Plotly** et propose plusieurs filtres pour une exploration dynamique.

![Dashboard RH Interactif](image/dashbord-interactivo.JPG)

---

## 1ï¸âƒ£ Indicateurs principaux (KPI)

En haut de lâ€™Ã©cran, trois indicateurs rÃ©sument la population filtrÃ©e :

- **1 999 EmployÃ©s** â†’ effectif total analysÃ©.  
- **96 525 â‚¬ Salaire Moyen** â†’ rÃ©munÃ©ration moyenne sur lâ€™Ã©chantillon.  
- **74,2/100 Performance Moyenne** â†’ score de performance global.  
- **7,0/10 Satisfaction Moyenne** â†’ note moyenne de satisfaction des employÃ©s.

ğŸ’¡ Ces KPI changent selon les filtres (dÃ©partement, plage dâ€™expÃ©rience).

---

## 2ï¸âƒ£ Distribution des Salaires (Histogramme empilÃ©)

**Description**
- Axe X : montant du **salaire**.  
- Axe Y : **effectif** (nombre dâ€™employÃ©s).  
- Couleurs : dÃ©partements (HR, Finance, Marketing, Sales, IT).  

**Analyse**
- La courbe montre une distribution proche dâ€™une **loi normale** (pic autour de 100 000 â‚¬).  
- Chaque couleur montre la **rÃ©partition par dÃ©partement** â†’ certains dÃ©partements ont plus de salariÃ©s dans les tranches hautes/basses.

**UtilitÃ©**
- RepÃ©rer des **Ã©carts de rÃ©munÃ©ration** entre dÃ©partements.  
- DÃ©tecter des anomalies (trop dâ€™employÃ©s trÃ¨s bas ou trÃ¨s hauts salaires).

---

## 3ï¸âƒ£ Performance vs Salaire (Nuage de points)

**Description**
- Axe X : **score de performance** (0â€“100).  
- Axe Y : **salaire**.  
- Chaque point = un employÃ©, colorÃ© par dÃ©partement.

**Analyse**
- La dispersion montre quâ€™un **meilleur score de performance** est globalement associÃ© Ã  un **salaire plus Ã©levÃ©**.  
- Toutefois, il existe de la **variabilitÃ©** (certains employÃ©s trÃ¨s performants mais peu payÃ©s â†’ opportunitÃ© dâ€™ajustement RH).  
- Les nuages par couleur permettent de comparer les dÃ©partements (ex. IT vs Sales).

**UtilitÃ©**
- VÃ©rifier la **corrÃ©lation performance â†” salaire**.  
- Identifier des **Ã©carts de traitement** Ã  poste Ã©quivalent.

---

## 4ï¸âƒ£ Performance Moyenne par DÃ©partement (Barres avec intervalles de confiance)

**Description**
- Chaque barre = un dÃ©partement.  
- Hauteur = **moyenne des scores de performance**.  
- Barres verticales = **intervalle de confiance** (variabilitÃ© intra-dÃ©partement).

**Analyse**
- Permet de comparer les **dÃ©partements entre eux**.  
- Ex. si Marketing < IT â†’ potentiel besoin de **formations ciblÃ©es**.  
- Un intervalle de confiance large = performance trÃ¨s hÃ©tÃ©rogÃ¨ne dans ce dÃ©partement.

**UtilitÃ©**
- Orienter les politiques de **formation** et dâ€™**encadrement**.  
- DÃ©finir des objectifs rÃ©alistes selon la distribution interne.

---

## 5ï¸âƒ£ Satisfaction par Ã‚ge et ExpÃ©rience (Heatmap)

**Description**
- Axe X : **expÃ©rience (annÃ©es)** â†’ 0â€“5, 5â€“10, 10â€“20, 20â€“30, 30+.  
- Axe Y : **tranche dâ€™Ã¢ge** â†’ 20â€“25, 25â€“30, â€¦, 45â€“55.  
- Couleurs = **note moyenne de satisfaction** (0â€“10).  

**Analyse**
- Les cases montrent les combinaisons Ã¢ge/expÃ©rience.  
- Ex. forte satisfaction chez les **employÃ©s expÃ©rimentÃ©s (30+ ans dâ€™exp.)** et certains jeunes profils.  
- Des zones plus rouges indiquent des tranches **moins satisfaites** (ex. 30â€“35 ans avec 20â€“30 ans dâ€™expÃ©rience).

**UtilitÃ©**
- Identifier des **populations Ã  risque de turnover**.  
- Ajuster des politiques RH selon la **carriÃ¨re** (mentorat, mobilitÃ© interne, reconnaissance salariale).

---

## 6ï¸âƒ£ Filtres interactifs

En haut du dashboard :
- **SÃ©lecteur de dÃ©partement** â†’ pour isoler HR, IT, Sales, etc.  
- **Plage dâ€™expÃ©rience (slider)** â†’ permet de comparer juniors vs seniors.  

ğŸ’¡ Ces filtres mettent Ã  jour **tous les graphiques** et les KPI.

---

## ğŸ¯ SynthÃ¨se

- Les **salaires** suivent une distribution normale avec quelques Ã©carts selon les dÃ©partements.  
- La **corrÃ©lation performance â†” salaire** existe mais nâ€™est pas parfaite â†’ ajustements RH possibles.  
- La **satisfaction** varie fortement selon lâ€™Ã¢ge et lâ€™expÃ©rience â†’ point crucial pour la rÃ©tention des talents.  
- Le dashboard permet aux RH de **cibler les actions** (formations, augmentations, politiques de motivation).

---

# ğŸ§ªStreamlit - Applications ML interactives
##1. Application Streamlit complÃ¨te
##Objectif : CrÃ©er une application web pour explorer des modÃ¨les ML

Cet outil Streamlit permet dâ€™explorer rapidement plusieurs **datasets classiques** (Iris, Vin, Breast Cancer), de **tester un modÃ¨le** (ex. SVM, Random Forest), dâ€™ajuster les **hyperparamÃ¨tres**, et de visualiser **mÃ©triques, rapports et distributions** â€” le tout en temps rÃ©el.

![AperÃ§u de lâ€™application](image/5.5-Streamlit-Applications-ML-interactives.JPG)

# ğŸ¤– Explorateur de ModÃ¨les Machine Learning

Ce dashboard interactif permet dâ€™explorer diffÃ©rents modÃ¨les de classification sur des jeux de donnÃ©es standards (Iris, Wine, Breast Cancer).  
Il fournit une interface intuitive pour sÃ©lectionner un dataset, ajuster les hyperparamÃ¨tres et visualiser les performances.

---

## ğŸ›ï¸ Panneau de ParamÃ¨tres (Ã  gauche)

- **Choisir un dataset** : liste dÃ©roulante permettant de sÃ©lectionner un jeu de donnÃ©es :
  - *Iris* : classification de fleurs
  - *Wine* : caractÃ©ristiques de vins
  - *Breast Cancer* : dÃ©tection de tumeurs bÃ©nignes ou malignes  

- **Kernel** : choix de la fonction noyau (ici `rbf`) pour un modÃ¨le SVM.  

- **Taille du test (%)** : curseur dÃ©finissant la proportion des donnÃ©es rÃ©servÃ©es au test (ici 20%).  

- **Instructions** : rappels Ã©tape par Ã©tape pour utiliser lâ€™explorateur :
  1. Choisissez un dataset  
  2. SÃ©lectionnez un modÃ¨le et ajustez ses paramÃ¨tres  
  3. Explorez les onglets dâ€™analyses  
  4. Modifiez les paramÃ¨tres et observez lâ€™impact en temps rÃ©el  

- **Conseils** :  
  - Commencez avec Random Forest (plus stable)  
  - Augmentez progressivement la complexitÃ©  
  - Observez lâ€™impact des hyperparamÃ¨tres  

---

## ğŸ“Š Indicateurs de Performance (en haut)

- **PrÃ©cision** : 0.947 (94,7% dâ€™exactitude globale du modÃ¨le).  
- **Ã‰chantillons Train** : 455 donnÃ©es utilisÃ©es pour lâ€™entraÃ®nement.  
- **Ã‰chantillons Test** : 114 donnÃ©es rÃ©servÃ©es pour lâ€™Ã©valuation.  
- **Features** : 30 variables explicatives utilisÃ©es par le modÃ¨le.  

Ces indicateurs donnent une vue synthÃ©tique de la robustesse du modÃ¨le entraÃ®nÃ©.

---

## ğŸ“‘ Rapport DÃ©tailÃ© (onglet sÃ©lectionnÃ©)

### Rapport de Classification
Tableau affichant les principales mÃ©triques pour chaque classe :

| Classe      | Precision | Recall | F1-Score | Support |
|-------------|-----------|--------|----------|---------|
| **malignant** | 0.922     | 1.000  | 0.86     | 43      |
| **benign**    | 1.000     | 0.959  | 0.98     | 71      |
| **accuracy**  | -         | -      | 0.947    | 114     |
| **macro avg** | 0.961     | 0.930  | 0.93     | 114     |
| **weighted avg** | 0.951 | 0.947  | 0.94     | 114     |

- **Precision** : proportion de prÃ©dictions correctes parmi celles donnÃ©es par le modÃ¨le.  
- **Recall** : proportion dâ€™Ã©lÃ©ments correctement identifiÃ©s parmi la classe rÃ©elle.  
- **F1-Score** : moyenne harmonique de precision et recall (Ã©quilibre).  
- **Support** : nombre dâ€™Ã©chantillons par classe.  

â¡ï¸ RÃ©sultat : le modÃ¨le est particuliÃ¨rement performant pour dÃ©tecter les cas bÃ©nins, tout en restant trÃ¨s bon pour les cas malins.

---

### Informations du Dataset

- **Nombre total dâ€™Ã©chantillons** : 569  
- **Nombre de features** : 30  
- **Nombre de classes** : 2 (*malignant* et *benign*)  
- **Ã‰chantillons dâ€™entraÃ®nement** : 455  
- **Ã‰chantillons de test** : 114  

#### Distribution des classes
- **Malignant** : 212 (37,3%)  
- **Benign** : 357 (62,7%)  

â¡ï¸ Les classes sont lÃ©gÃ¨rement dÃ©sÃ©quilibrÃ©es (plus de cas bÃ©nins que malins), ce qui peut influencer le recall.

---

## ğŸ¯ InterprÃ©tation Globale

- Le modÃ¨le atteint une prÃ©cision Ã©levÃ©e (**94,7%**), adaptÃ©e pour une tÃ¢che mÃ©dicale sensible.  
- Les mÃ©triques montrent un bon compromis entre **rappel** (ne pas manquer de cas malins) et **prÃ©cision** (Ã©viter les faux positifs).  
- La rÃ©partition train/test est Ã©quilibrÃ©e, garantissant une Ã©valuation fiable.  

ğŸ‘‰ Ce type de dashboard permet aux Data Scientists et praticiens de **tester rapidement diffÃ©rents modÃ¨les et configurations** pour observer leur impact sur la performance.


---

# ğŸ“Š Dashboard de Monitoring â€“ Analyse DÃ©taillÃ©e


![AperÃ§u de lâ€™application](image/5.5-monitoring-ML-dashborad-2.JPG)


Ce dashboard illustre un systÃ¨me de **surveillance en temps rÃ©el** des modÃ¨les de Machine Learning. Il est composÃ© de plusieurs sections qui fournissent des informations sur lâ€™Ã©tat du systÃ¨me, la dÃ©rive des donnÃ©es et les performances opÃ©rationnelles.

---

## ğŸ”” Alertes Automatiques

- **Barre verte** : indique que *tous les indicateurs sont dans les normes*.  
- Cela signifie quâ€™aucun seuil critique nâ€™a Ã©tÃ© dÃ©passÃ© (prÃ©cision, latence, mÃ©moire, etc.).  
- Le bouton **Â« RafraÃ®chir les DonnÃ©es Â»** permet de mettre Ã  jour les graphiques et les mÃ©triques en direct.

---

## ğŸ“ˆ Analyse de DÃ©rive des DonnÃ©es

Cette partie mesure la **stabilitÃ© des donnÃ©es dâ€™entrÃ©e** utilisÃ©es par le modÃ¨le.  
Une dÃ©rive trop importante peut indiquer que les donnÃ©es de production ne ressemblent plus aux donnÃ©es dâ€™entraÃ®nement, ce qui risque de rÃ©duire la performance du modÃ¨le.

### Graphiques Ã  gauche â€“ *Moyenne des features*
- **Feature 1 â€“ Moyenne (ligne bleue)** : montre lâ€™Ã©volution de la valeur moyenne de la premiÃ¨re variable explicative.  
  - Ici, la moyenne reste relativement stable avec une lÃ©gÃ¨re tendance haussiÃ¨re.  
- **Feature 2 â€“ Moyenne (ligne rouge)** : suit la moyenne de la deuxiÃ¨me variable.  
  - On observe des fluctuations mais elle reste proche de zÃ©ro, ce qui est acceptable.  

â¡ï¸ Ces courbes permettent de dÃ©tecter un Ã©ventuel *shift de distribution*.

### Graphiques Ã  droite â€“ *Ã‰cart-type des features*
- **Feature 1 â€“ Ã‰cart-type (bleu)** : mesure la variabilitÃ© des donnÃ©es pour la Feature 1.  
  - On observe des oscillations normales, signe dâ€™une variabilitÃ© stable.  
- **Feature 2 â€“ Ã‰cart-type (rouge)** : suit la dispersion de la Feature 2.  
  - Ici aussi, les variations sont rÃ©guliÃ¨res, aucune dÃ©rive anormale dÃ©tectÃ©e.  

â¡ï¸ Une hausse brutale de lâ€™Ã©cart-type signalerait une instabilitÃ© dans les donnÃ©es.

---

## ğŸ“Š RÃ©sumÃ© du Monitoring

Ce tableau prÃ©sente les **indicateurs clÃ©s du modÃ¨le et du systÃ¨me**, comparÃ©s aux seuils attendus.

| MÃ©trique   | Valeur Actuelle | Seuil | Statut | InterprÃ©tation |
|------------|----------------|-------|--------|----------------|
| **Accuracy** | 0.910 | 0.900 | âœ… OK | Le modÃ¨le conserve une prÃ©cision au-dessus du seuil critique. |
| **Latence** | 65 ms | 100 ms | âœ… OK | Les prÃ©dictions sont rapides, en dessous de la limite fixÃ©e. |
| **Volume** | 1,511 | N/A | âœ… N/A | Nombre dâ€™Ã©chantillons traitÃ©s, indicatif de la charge du systÃ¨me. |
| **Erreurs** | 4.9% | 10% | âœ… OK | Taux dâ€™erreurs reste sous contrÃ´le. |
| **MÃ©moire** | 2.7 GB | 4.0 GB | âœ… OK | La consommation mÃ©moire est dans la limite autorisÃ©e. |
| **CPU** | 56% | 80% | âœ… OK | Lâ€™utilisation du processeur reste modÃ©rÃ©e. |

---

## ğŸ¯ InterprÃ©tation Globale

- âœ… Tous les indicateurs sont **dans le vert** : le systÃ¨me est stable.  
- ğŸ“‰ Aucune dÃ©rive majeure dÃ©tectÃ©e sur les features surveillÃ©es.  
- ğŸš¦ Le tableau de monitoring montre une **marge de sÃ©curitÃ© confortable** (accuracy > seuil, latence < limite, mÃ©moire < seuil).  

En rÃ©sumÃ©, le modÃ¨le est **opÃ©rationnel et fiable** dans ce contexte de monitoring continu.

------


![AperÃ§u de lâ€™application](image/5.5-monitoring-ML-dashborad.JPG)


# ğŸ“Š Dashboard de Monitoring ML â€” Explication dÃ©taillÃ©e

Ce tableau de bord suit en continu la **santÃ© dâ€™un modÃ¨le de Machine Learning** et de son **infrastructure**.  
Il se compose de 3 zones : **MÃ©triques en Temps RÃ©el**, **Tendances de Performance**, et **Ressources SystÃ¨me**.

![AperÃ§u](images/5.5-monitoring-ML-dashborad.JPG)

---

## 1) ğŸŸ¢ MÃ©triques en Temps RÃ©el (cartes KPI)

- **Accuracy : 0.910**  
  Proportion des prÃ©dictions correctes sur la fenÃªtre dâ€™observation rÃ©cente.  
  > InterprÃ©tation : au-dessus du seuil de 0.90 â†’ **OK** (modÃ¨le globalement fiable).

- **Latence (ms) : 65**  
  Temps moyen pour retourner une prÃ©diction (du `request_in` Ã  `response_out`).  
  > InterprÃ©tation : infÃ©rieur au seuil de 100 ms â†’ **OK** (service rÃ©actif).

- **PrÃ©dictions/jour : 1 511**  
  Volume traitÃ© sur 24h. Sert Ã  dÃ©tecter des changements de trafic (pics/sous-charge).  
  > InterprÃ©tation : volume stable â†’ **OK** (charge rÃ©guliÃ¨re).

- **Taux dâ€™Erreur : 4.8%**  
  Part des requÃªtes en Ã©chec (exceptions, timeouts) **ou** des prÃ©dictions explicitement invalidÃ©es par des rÃ¨gles mÃ©tiers.  
  > InterprÃ©tation : sous le seuil critique de 10% â†’ **OK**.

**Ã€ retenir** : les quatre KPI sont **dans le vert**. Aucune alerte immÃ©diate.

---

## 2) ğŸ“ˆ Tendances de Performance (sÃ©ries temporelles)

### 2.1 Ã‰volution de la PrÃ©cision du ModÃ¨le (ligne)
- **Ce que lâ€™on voit** : la prÃ©cision quotidienne (ou par crÃ©neau horaire) avec une **ligne de seuil dâ€™alarme Ã  0.90** (pointillÃ©s rouges).  
- **Comment lire** : la courbe reste au-dessus du seuil, avec de lÃ©gÃ¨res oscillations.  
- **Ce que Ã§a implique** : **pas de dÃ©rive de performance** significative. Les variations normales peuvent venir du mix utilisateurs, des versions de donnÃ©es, ou de la saisonnalitÃ©.

**Actions si anomalie**  
- Si la prÃ©cision passe **sous 0.90** de maniÃ¨re persistante :  
  1) vÃ©rifier les **donnÃ©es dâ€™entrÃ©e** (schÃ©ma, encodage, features manquantes),  
  2) comparer les distributions production vs entraÃ®nement (**dÃ©rive**),  
  3) rÃ©Ã©valuer le **seuil de dÃ©cision** ou relancer un **rÃ©entraÃ®nement**.

---

### 2.2 Ã‰volution de la Latence (ligne)
- **Ce que lâ€™on voit** : la latence moyenne avec une **ligne dâ€™alerte ~80â€“100 ms** (pointillÃ©s jaunes/oranges selon lâ€™implÃ©mentation).  
- **Observation** : une ou deux **pointes** (spikes) ponctuelles, sinon la plupart des points **< 80 ms**.  
- **InterprÃ©tation** : service **globalement fluide** ; les pics pourraient correspondre Ã  des **pics de charge**, **GC**, ou une **dÃ©pendance externe** lente.

**Actions si anomalie**  
- Si des pics se multiplient :  
  - activer un suivi **p95/p99** (latence queue),  
  - **cache** sur features ou sorties souvent rÃ©utilisÃ©es,  
  - profiling (CPU/GPU), connection pooling, **autoscaling**.

---

### 2.3 Volume de PrÃ©dictions par Jour (barres)
- **Ce que lâ€™on voit** : barres quasi constantes autour de **1 500 prÃ©dictions/jour**.  
- **InterprÃ©tation** : trafic **stable** â†’ idÃ©al pour comparer les performances Ã  pÃ©rimÃ¨tre constant.  
- **UtilitÃ©** : un **effondrement** ou une **explosion** du volume peut expliquer des changements de latence/erreurs (ex. afflux marketing, incident amont/aval).

---

### 2.4 Ã‰volution du Taux dâ€™Erreur (ligne)
- **Ce que lâ€™on voit** : ligne avec **seuil critique Ã  10%** (pointillÃ©s rouges).  
- **Observation** : oscillations dans une plage **3â€“8%**, quelques crÃªtes mais **sous 10%**.  
- **InterprÃ©tation** : erreurs **contenues** ; surveiller les montÃ©es corrÃ©lÃ©es (ex. hausse latence + erreurs = saturation).

**Actions si anomalie**  
- Si > 10% ou croissance continue :  
  - inspecter logs/trace **par code dâ€™erreur** (timeout, 5xx, validation),  
  - vÃ©rifier **versions** (modÃ¨le, feature store, schÃ©mas),  
  - mettre en place **circuit breaker** et **retries**.

---

## 3) ğŸ–¥ï¸ Ressources SystÃ¨me

### 3.1 Utilisation MÃ©moire (GB) â€” avec **Limite 4 GB**
- **Ce que lâ€™on voit** : tendance globale **montante mais sous 4 GB**.  
- **InterprÃ©tation** : pas de fuite Ã©vidente. Les **micro-spikes** peuvent Ãªtre liÃ©s aux batchs ou au chargement de modÃ¨les.

**Actions si anomalie**  
- Si dÃ©passements frÃ©quents de la **limite 4 GB** :  
  - charger le modÃ¨le **une seule fois** (singleton),  
  - libÃ©rer les buffers temporaires,  
  - rÃ©duire la **taille de batch**,  
  - activer une **limitation de concurrence** (workers).

---

### 3.2 Utilisation CPU (%) â€” **Seuil dâ€™alerte ~80%**
- **Ce que lâ€™on voit** : une **grosse montÃ©e** initiale, puis une stabilisation **< 60%** la plupart du temps, avec quelques oscillations.  
- **InterprÃ©tation** : capacitÃ© **disponible** ; les pics peuvent coÃ¯ncider avec des recalculs, un **autoscaling** ou le **warm-up**.

**Actions si anomalie**  
- Si > 80% de faÃ§on persistante :  
  - augmenter le **replica count** / autoscaler,  
  - profiler le code (vectorisation, I/O),  
  - Ã©purer les prÃ©/post-traitements lour


# âœ… Bonnes pratiques pour les dashboards

## ğŸ¨ Design UX
| Bonnes pratiques | Explication |
|------------------|-------------|
| Interface intuitive et claire | Un design Ã©purÃ© facilite la comprÃ©hension immÃ©diate. |
| Temps de chargement rapide | Les utilisateurs nâ€™attendent pas â†’ meilleure expÃ©rience. |
| Responsive design | Le tableau de bord sâ€™adapte aux Ã©crans (desktop, tablette, mobile). |
| Navigation facile | AccÃ¨s rapide aux sections â†’ gain de temps. |
| Feedback visuel immÃ©diat | Lâ€™utilisateur reÃ§oit une confirmation ou un retour instantanÃ© (ex. chargement, mise Ã  jour). |

---

## âš¡ Performance
| Bonnes pratiques | Explication |
|------------------|-------------|
| Cache des donnÃ©es coÃ»teuses | Ã‰vite de recalculer sans cesse les mÃªmes requÃªtes lourdes. |
| Pagination pour gros datasets | AmÃ©liore la vitesse en affichant par lot. |
| Chargement asynchrone | Permet de charger certaines parties sans bloquer tout le dashboard. |
| Optimisation des requÃªtes | RÃ©duit le temps de rÃ©ponse cÃ´tÃ© base de donnÃ©es/API. |
| Compression des donnÃ©es | AccÃ©lÃ¨re le transfert entre serveur et client. |

---

## ğŸ”§ Maintenance
| Bonnes pratiques | Explication |
|------------------|-------------|
| Code modulaire et rÃ©utilisable | Favorise la maintenabilitÃ© et rÃ©duit les duplications. |
| Configuration externalisÃ©e | ParamÃ¨tres gÃ©rÃ©s hors du code (fichiers `.env`, `.yaml`). |
| Logging et monitoring | Suivi des erreurs et performances pour anticiper les pannes. |
| Tests automatisÃ©s | Garantissent la fiabilitÃ© lors des mises Ã  jour. |
| Documentation utilisateur | Facilite la prise en main par dâ€™autres personnes. |

---

# ğŸ› ï¸ Outils et technologies recommandÃ©s

| Outil             | Type                        | Avantages                                   | Cas dâ€™usage                                |
|-------------------|-----------------------------|---------------------------------------------|--------------------------------------------|
| **Plotly**        | Graphiques interactifs      | Riche, interactif, prÃªt pour le web         | Graphiques complexes, export web           |
| **Streamlit**     | Application web             | Simple, rapide, Python pur                  | Prototypes, dÃ©monstrations                 |
| **Dash**          | Dashboard web               | TrÃ¨s personnalisable, robuste               | Applications de production                 |
| **Jupyter Widgets** | Notebooks interactifs     | IntÃ©grÃ© Ã  Jupyter, exploration rapide       | Recherche, prototypage                     |
| **Bokeh**         | Visualisation web           | Haute performance, big data                 | Grandes datasets, temps rÃ©el               |

---

ğŸ“Œ **Conseil pratique** :  
Commencez par **Streamlit** pour prototyper rapidement, utilisez **Plotly** pour les graphiques avancÃ©s, et migrez vers **Dash** pour une mise en production robuste.  
Pour la recherche exploratoire â†’ **Jupyter Widgets**, et pour les trÃ¨s gros volumes de donnÃ©es â†’ **Bokeh**.

# ğŸš€ Exercice Pratique GuidÃ© â€” CrÃ©ez votre premier Dashboard

ğŸ‘‰ Suivez ces **7 Ã©tapes** pour construire un dashboard interactif de A Ã  Z :

---

## ğŸ“‹ Ã‰tapes Ã  suivre

1ï¸âƒ£ **PrÃ©paration** ğŸ› ï¸  
CrÃ©ez lâ€™environnement virtuel et installez les dÃ©pendances nÃ©cessaires.

2ï¸âƒ£ **Dataset** ğŸ“Š  
Choisissez un dataset qui vous intÃ©resse (Iris, Titanic, ou vos propres donnÃ©es).

3ï¸âƒ£ **Graphiques** ğŸ“ˆ  
CrÃ©ez 3-4 graphiques **Plotly interactifs** dans le dossier `scripts/`.

4ï¸âƒ£ **Application** ğŸ’»  
DÃ©veloppez une application **Streamlit** dans le dossier `streamlit_apps/`.

5ï¸âƒ£ **InteractivitÃ©** ğŸ›ï¸  
Ajoutez des filtres et des contrÃ´les utilisateurs pour enrichir lâ€™expÃ©rience.

6ï¸âƒ£ **Test** âœ…  
Lancez lâ€™application et vÃ©rifiez que toutes les fonctionnalitÃ©s marchent.

7ï¸âƒ£ **Partage** ğŸ¤  
Montrez vos dashboards Ã  des collÃ¨gues et collectez leurs retours pour amÃ©liorer.

---

## âœ… Checklist de validation

### ğŸŒ Environnement
- âœ”ï¸ Environnement virtuel crÃ©Ã© et activÃ©  
- âœ”ï¸ Toutes les dÃ©pendances installÃ©es  
- âœ”ï¸ Script de test exÃ©cutÃ© avec succÃ¨s  
- âœ”ï¸ Structure de projet crÃ©Ã©e  
- âœ”ï¸ `requirements.txt` gÃ©nÃ©rÃ©  

### ğŸ“¦ Applications
- âœ”ï¸ Dashboard **Streamlit** fonctionnel  
- âœ”ï¸ Application **Dash** testÃ©e  
- âœ”ï¸ Widgets **Jupyter** opÃ©rationnels  
- âœ”ï¸ Graphiques **Plotly** interactifs  
- âœ”ï¸ Monitoring dashboard crÃ©Ã©  

---

âœ¨ **Astuce bonus :**  
Nâ€™ayez pas peur de tester plusieurs datasets et de varier les graphiques (histogrammes, heatmaps, barres empilÃ©es, sÃ©ries temporelles).  
Un bon dashboard = **clartÃ© + interactivitÃ© + esthÃ©tique** ğŸ¨

-------------


![AperÃ§u](images/test-rapide.JPG)


---------------
